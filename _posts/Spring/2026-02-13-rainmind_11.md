---
title: "Project : RainMind 개발일지 - 11 [최적화 수행 기록]"
last_modified_at: 2026-02-14
# date: 2026-01-23 01:00:00 +0900
categories:
  - Rainmind
---  

본 글을 최적화 수행 기록(수치화 포함)에 관한 글이다.  
수치적 요약 및 스크립트/사용한 PromQL 쿼리, 정제된 데이터는 다음 포스팅에 기록할 예정이다.  
  
1) **회원가입 기능**  
유저 100명이, 3분동안 계속 회원가입 로직을 수행할 때를 모니터링해서 병목 지점이 있는지 찾고자 했다.  
우선 그냥 돌렸을때이다.  
![whyf](/pictures/grafana_signup/grafana_what/DBconnectpoolbef/why.JPG)
??? 응답시간이 k6 EC2에서는 거의 4초가 걸린다(쿼리 = 1000 *
(
  rate(http_server_requests_seconds_sum{job="rainmind-app", uri="/v1/auth/user/register"}[1m])
  /
  rate(http_server_requests_seconds_count{job="rainmind-app", uri="/v1/auth/user/register"}[1m])
)).  
  
output json을 뜯어보자.  
![whyfs](/pictures/grafana_signup/grafana_what/DBconnectpoolbef/3.JPG)  
찾았다.  
즉 회원가입 API에서 무거운 연산을 수행하기 때문에, 다른 요청들이 기다리는 시간이 거의 대부분이었던 것이다.  
  
혹시나 DB 커넥션 풀(Hikari 기본 = 10) 때문인지 궁금하여, application.yaml에 기본 커넥션 풀 사이즈를 5배 늘여서 해보았지만  
  
![whyfs2](/pictures/grafana_signup/grafana_what/DBconnectpoolaft/2.JPG)  
똑같았다. 또한 서버 EC2에서 top으로 CPU 사용량을 보았더니 97까지 치솟았다.  
  
따라서 회원가입 서비스 로직의 암호화 연산이 병목 지점임을 파악했다. gensalt 인자 값을 4로 주어(기본 = 10), CPU 연산을 훨씬 줄여보았고 결과는  
  
![yesyes](/pictures/grafana_signup/grafana_what/bcryptafter/ms.JPG)
![yesyess](/pictures/grafana_signup/grafana_what/bcryptafter/1.JPG)  
평균 응답시간 및 p(95)를 각각 3.68s, 3.96s -> 153.89ms, 415.77ms로, 거의 9배 가까이 개선할 수 있었다.  
  
그러나, BCrypt 인자를 4로 줄이는 것은, 연산량이 지수적으로 감소하기 때문에 보안적으로 매우 위험하다. 따라서, k8s의 자동 확장 기능 혹은, nginx 등을 이용하여 EC2 서버를 하나 더 띄운 다음 트래픽을 분산시키는 것이 적절한 조치임을 결론내렸다.  
  
2) **로그인 기능**  
현재 로그인 기능은, nickname/password를 받아서 user가 DB에 있고 -> 비밀번호가 일치하면 응답을 반환하는 형식이다.  
그러나 같은 IP에서 지속적으로 nickname/password 입력 공격이 온다면 DB 연산 및 BCrypt CPU 연산으로 인해 서버가 심히 느려질 것이다.  
  
따라서, 해당 IP를 redis에 캐싱 후 1분동안 60회가 넘어가는 요청이 오면 해당 IP를 3분동안 차단하여 CPU 자원과 DB 연산을 보호한다.

(전)  
![초당1만회](/pictures/grafana_logindefense/before/초당1만회.JPG)  
![2](/pictures/grafana_logindefense/before/2.JPG)  
  
(후)  
![3](/pictures/grafana_logindefense/after/3.JPG)  
![22](/pictures/grafana_logindefense/after/2.JPG)  
  
(주요 지표 쿼리)  
- max_over_time(hikaricp_connections_pending[1m]) : DB 커넥션 획득하기 위해 대기중인 스레드 수의 max  
- max_over_time(hikaricp_connections_active[1m]) : 실제로 DB를 사용중인 커넥션 수  
  
또한 응답시간(avg, p(95)) 또한 약 3배 개선되었음을 알 수 있다.  
  
해당 방법은 같은 IP에서 무작위 nickname / password 대입 공격을 하는 것을 방어하는데 효과적이다.  
그러나, 같은 AP(Access Point)를 사용한다면 외부에서 보는 IP는 동일하므로, 정상적인 유저들까지 피해를 입을 수 있다.  
  
본 실험에서는 이를 완화하기 위해 IP를 단순히 짧은 시간(3분) 차단하였지만, 더욱 세부적으로 정책을 도입한다면 특정 IP에서 일정 threshold 이상 요청이 쌓이게 된다면 캡챠와 같은 프로그램을 도입하여 정상적인 사용자를 걸러낸 후, 해당 경우에서만 nickname 과 같은 요청의 정보를 추가적으로 저장하는 것이 좋을 것으로 판단된다. 처음부터 ip:nickname 조합을 모두 저장하면 redis 메모리가 버티지 못할 것이다.  
  
3) **스케줄 생성 기능**  
현재 어플리케이션의 꽃이자, 가장 중요한 부분인 스케줄 생성 및 redis기능 확인 부분이다.  
우선 스케줄 생성 기능부터 로직 다시 점검하였고, 그 결과 유저가 스케줄을 마구잡이로 생성하는 것을 막기 위한 **scheduleRepository.findAllByUserId(user.id!!).size** 부분이 병목이 될 수 있음을 예상하였다.  
  
왜냐하면 findAllByUserId의 반환형은 List<엔티티> 인데, 이렇게 되면 findAllByUserId시 해당하는 모든 객체들을 힙메모리에 들고오게 되므로, 메모리 사용량 및 응답시간 측면에서 매우 불리하다.  
  
(JPA를 쓰더라도 동일하다. 지연로딩 없이 즉시 힙에 모든 객체를 다 들고온다. 만약 entity 내부에 또다른 entity가 있고, 이를 참조한다면 지연로딩 대상이 될 것이다)  
  
해당 가설을 검증하기 위해, 잠시 인당 스케줄 제한 횟수를 해제하고, DB에 user 200명이 각각 1000개의 스케줄을 만들어놓는다.  
이후, findAllByUserId() vs countByUserId()의 성능을 비교한다.  
  
아래처럼 seed_1부터 seed_200까지 200명의 유저들과 각 유저당 1000개의 스케줄을 할당해주고,
![할당](/pictures/schedulemake/스케줄삽입성공.JPG)  

JVM의 heap, GC 작동시간, 힙 메모리 사용률을 중점적으로 관찰한다.
< 이전 >  
![진짜1](/pictures/schedulemake/before/진짜1.JPG)
![진짜2](/pictures/schedulemake/before/진짜2.JPG)  
  
< 이후 : 해당 부분을 countByUserId()로 바꿈 >  
![진짜1](/pictures/schedulemake/after/진짜1after.JPG)
![진짜2](/pictures/schedulemake/after/2after.JPG)  
  
테스트는 의도적으로 fail하도록 설계되었으므로, 테스트 결과는 성공적이며 평균/p(90)/p(95) 응답시간을 포함한 DB 커넥션 풀, JVM 메모리 전반의 수치가 상당히 개선되었음을 확인할 수 있었다.  
  
그러나 이 방식에는 치명적인 약점이 있다. 멀티스레드 환경에서 race condition이 발생할 수 있다. 
아래 그림은 seed_201 가상의 유저를 만들고, VU = 2000명이 동시에 스케줄을 생성하는 상황을 만들고, 실제 DB에 삽입된 스케줄의 개수를 보여준다.  
![정합성](/pictures/schedulemake/after/count동시성이슈.JPG)  
  
서비스 로직에서는 count >= 30이면 예외 던지기로 막는데, 해당 로직으로는 역부족임을 바로 알 수 있다. 바로 터진다.  
일정 제한이 1인당 29개까지인데, 28개인 상황에서 두 개 이상의 스레드가 countByUserId()를 호출한다면 모두 28개를 반환받아 일정을 삽입하는 로직을 수행하기 때문이다.  
  
Spring은 기본적으로 스레드 풀을 사용하는 멀티스레드 환경이기 때문에, 반드시 이를 고려하며 서비스 로직을 설계해야 한다.  
  
이는 이전 포스팅에서 다뤘던 낙관적 락, 비관적 락, 네이티브 쿼리(atomic update)로 해결할 수 있다.  
JPA는 참 편리하지만, 복잡한 쿼리를 직접 만들어주는 기능이 없으므로 네이티브 쿼리 작성법에 대해 어느정도 숙지하여야 하는 것이 필수이다. (그래서 프로그래머스 sql을 열심히 풀고 있다)
  
네이티브 쿼리로 아래처럼 레포지토리 함수를 짠 후,
```kotlin
@Modifying
@Transactional
@Query(value = """INSERT INTO schedules (user_id, title, location_id, start_at, end_at) 
  SELECT :userId, :title, :locationId, :start_at, :end_at
  WHERE (SELECT COUNT(*) FROM schedules WHERE user_id = :userId) <= 29
""")  
  
@Query(value = """SELECT LAST_INSERT_ID()""")
```  
2000명의 VU에 대해 30000번이 넘는 요청을 보내보면  
![정합성](/pictures/schedulemake/after/count동시성이슈해결.JPG)  
  
정확히 30개만이 insert된 것을 볼 수 있다.  
  
![진짜1정합성](/pictures/schedulemake/after2(atomicquery)/1.JPG)
![진짜2정합성](/pictures/schedulemake/after2(atomicquery)/2.JPG)  
  
특히 응답시간이 크게 감소한 것을 확인할 수 있다.
  
4) **그외 개선 포인트(시스템 관점)**  
- shedlock과 alarm dequeue를 같이 붙인 것 & retryPending()에서, outbox의 PENDING signal을 전부 가져오는것:  
  
- 애초에 DB native query를 사용하지 않고, redis에 count 정보를 임시 저장하는 방안 고려:
  
