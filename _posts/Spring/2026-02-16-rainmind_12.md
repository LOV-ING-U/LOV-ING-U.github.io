---
title: "Project : RainMind 개발일지 - 12 [1번째 최적화 수행 기록(수치화)]"
last_modified_at: 2026-02-16
# date: 2026-01-23 01:00:00 +0900
categories:
  - Rainmind
---  
  
이전 글에서 사용한 스크립트와 PromQL 쿼리, 데이터 수치화를 기록한다.  
  
1) **회원가입 기능**  
- **문제 제시**: 수백명의 유저가 지속적으로 회원가입을 수행할 때 처리 속도가 낮아지는 병목 현상 발생.  
  
- **해결**: 문제 파악을 위해 100명의 유저가 3분동안 지속적으로 회원가입 로직을 수행하는 스크립트를 작성.  
  
- **사용 스크립트**:  
  
```javascript
import http from 'k6/http';
import { check, sleep } from 'k6';
import { uuidv4 } from 'https://jslib.k6.io/k6-utils/1.4.0/index.js';
import { Counter } from 'k6/metrics';

export const options = {
    duration: '3m',
    vus: 100
};

const BASE_URL = __ENV.BASE_URL;
const created = new Counter('created_201');
const dup = new Counter('dup_409');

export default function() {
    const nickname = `user_${uuidv4().substring(0, 8)}_${__VU}_${__ITER}`;
    const res = http.post(
        `${BASE_URL}/v1/auth/user/register`,
        JSON.stringify({
            nickname,
            password: 'password12345678',
            region_name: 'Seoul'
        }),
        {
            headers: {
                'Content-Type': 'application/json'
            }
        }
    );

    check(res, {
        'register, or duplicate': (r) => r.status == 201 || r.status == 409
    });

    if(res.status == 201) created.add(1);
    if(res.status == 409) dup.add(1);
}
```  
- **측정 지표**: 평균 응답시간, p(90) / p(95) / max 응답시간, RPS(Request Per Second)  
(결과)    
  
| avg | p(90) | p(95) | max | RPS(req / s) |   
| --- | ----- | ----- | --- | ------------ |  
| 3.68s | 3.91s | 3.96s | 6.14s | 27.044926 |  
  
특이사항: http_req_waiting 즉 대부분의 시간을 HTTP request 이후 서버로부터 응답을 받을때까지 기다리는데 사용함.  
  
- **병목 현상에 대한 가설**: **(1)** DB 커넥션 풀 부족에 따른 스레드 대기 현상, **(2)** 회원가입 시 비밀번호 암호화(무거운 연산 수행)에 따른 작업시간 증가  
  
- **가설 검증 (1) - DB 커넥션 풀 증가**: application.yaml 파일에 hikari.maximum-pool-size를 default = 10에서 50으로 custom 설정.  
  
(결과)  
  
| avg | p(90) | p(95) | max | RPS(req / s) |   
| --- | ----- | ----- | --- | ------------ |  
| 3.93s | 4.19s | 4.33s | 6.46s | 25.325949 |  

여전히 CPU 사용률이 90% 대이며, 커넥션 풀의 수를 늘였음에도 불구하고 변화가 없어 CPU가 수행하는 무거운 연산에 의해 응답이 지연된 것이라 판단하여 다음 실험 수행.  
  
- **가설 검증 (2) - 비밀번호 암호화 연산 감소**: UserSignUpService.kt의 gensalt() 인자로 4를 전달(default = 10).  
  
(결과)  
    
| avg | p(90) | p(95) | max | RPS(req / s) |   
| --- | ----- | ----- | --- | ------------ |  
| 153.89ms | 344.7ms | 415.77ms | 1.44s | 648.711365 |  
  
CPU 사용률은 80% 대로 소폭 감소, 그러나 **RPS가 약 25배 증가 및 p(95)는 약 20배 개선**되어 그만큼 요청을 더욱 처리할 수 있었던 것으로 판단됨.  
  
BCrypt는 gensalt()에 주는 인자의 2의 거듭제곱 만큼 키 확장(BCrypt 내부적으로 가진 거대한 숫자의 테이블을 계속 변경)이 수행되어, CPU가 의도적으로 많은 연산을 하도록 설계되었다. 따라서, 해당 인자를 늘이면 보안은 견고해지나 속도가 느려지고, 해당 인자를 줄이면 보안이 약해진다.   
  
따라서, 속도를 중요시한다면 인자를 조금 줄이거나, 보안이 중요하다면 현행 유지를 하면 될 것으로 판단됨. 아니면 Argon2와 같은 대체 알고리즘을 고려해볼 수 있을것이다.  
  
2) **로그인 기능**  
- **문제 제시**: 악의적인 유저가 임의의 아이디 및 비밀번호로 무작위 공격을 시도하여 서버의 CPU 자원을 낭비(특히 BCrypt 연산)하여 서버를 공격할 수 있음.  
  
- **해결**: 외부 저장소 Redis를 사용하여, 최근 1분간 로그인 시도를 수행중인 IP의 로그인 시도 횟수를 기록함. 이후 일정량 이상 요청이 오면, 해당 IP를 짧은 시간(3분) 차단하여 CPU 자원을 보호한다. DB table을 하나 더 추가하는 방안도 고려하였으나, 악의적인 공격으로 인해 DB 커넥션 풀이 고갈될 수 있으므로 외부 저장소를 사용함.  
  
- **사용 스크립트**: 
  
```javascript
import http from 'k6/http';
import { check, sleep } from 'k6';

export const options = {
  scenarios: {
    login_attack: {
      executor: 'constant-arrival-rate',
      rate: 10000,
      timeUnit: '1s',
      duration: '3m',
      preAllocatedVUs: 50,
      maxVUs: 200,
    },
  },
};

const BASE_URL = __ENV.BASE_URL;

export default function () {
  const id = Math.floor(Math.random() * 200);
  const nickname = `seed_${id}`;

  const password = 'wrong_password';

  const res = http.post(
    `${BASE_URL}/v1/auth/user/login`,
    JSON.stringify({
        nickname,
        password
    }),
    {
        headers: {
            'Content-Type': 'application/json'
        }
    }
  );

  check(res, {
    'blocked(429) or unauthorized(401/404)': (r) => r.status === 429 || r.status === 401 || r.status === 404,
  });

  sleep(0.01);
}
```  
  
- **측정 지표**: **(1)** 응답 시간(평균, p(90), p(95), max) 및 RPS, **(2)** max_over_time(hikaricp_connections_active[1m]) = 실제 DB를 사용중인 커넥션의 수   
  
(결과 - Redis 차단 캐시 도입 이전)    
  
| avg | p(90) | p(95) | max | RPS(req / s) | active DB connection(개 / min) |   
| --- | ----- | ----- | --- | ------------ | ------------------------------ |  
| 223.88ms | 455.8ms | 602.69ms | 1.42s | 851.823838 | 약 3.83 |    
  
(결과 - Redis 차단 캐시 도입 이후)  
시간이 지나며 429 요청이 많아지므로, 방어 로직은 정상 작동함을 확인할 수 있다.  
  
| avg | p(90) | p(95) | max | RPS(req / s) | active DB connection(개 / min) |     
| --- | ----- | ----- | --- | ------------ | ------------------------------ |  
| 64.09ms | 123.08ms | 180.17ms | 3.01s | 2669.172776 | 1.08 |  
  
또한, 평균적인 DB 커넥션 풀 사용 개수가 약 3.54배 개선되었으며, p(90) 및 p(95) 또한 각각 3.7배 / 3.35배 개선되었다.  
  
이는 Redis 방어 로직으로 서버 내부 CPU 자원 및 DB 커넥션 풀을 보호했음을 보여준다.  
  
그러나, 실세계에서는 단순 IP만으로 차단하는 것은 부적절하다. 왜냐하면, 카페와 같은 공공 장소에서는 대부분이 공유기와 같은 AP를 사용하므로, 외부에서 보았을 때는 해당 AP를 사용하는 사용자의 IP는 모두 동일하다. 즉 정상적인 이용자들까지 차단해버리는 위험이 존재한다.  
  
따라서, 단순 IP만으로 차단하는 것은 위험하며, 비정상적으로 접속이 많은 IP를 '의심 IP'등으로 기억한 다음 캡챠와 같은 인증을 도입하거나, 비정상적으로 많이 입력되는 아이디 / 비밀번호 패턴을 차단하는 등 보다 세분화된 방법이 필요할 것이다.  
  
3) **스케줄 생성 기능**  
- **문제 제시**: ScheduleService.kt의 scheduleRepository.findAllByUserId(user.id!!).size 부분은, JVM 힙 메모리에 엔티티 객체들을 모두 들고오므로 메모리 사용량 측면과 응답 시간(가비지 콜렉터의 stop the world로 인해 비즈니스 로직이 느려질 수 있다) 측면에서 불리하다.  
  
- **해결**: scheduleRepository.countByUserId(user.id!!)로 힙 메모리에 객체들을 모두 들고오지 않고, 개수만 반환하는 함수를 사용한다. 테스트 시, 각 200명의 유저 당 1000개의 스케줄을 미리 할당해 둔 후, 각 요청마다 엔티티 객체들을 모두 가져오는 스크립트를 구성하여 전후 변화를 관찰한다. 또한 SELECT 문법과 INSERT 문법을 조합한 native query 방식에서도 속도의 변화를 관찰한다.  
  
- **사용 스크립트**: 
  
```javascript
import http from 'k6/http';
import { check } from 'k6';

export const options = {
   scenarios: {
    steady_800rps: {
      executor: 'constant-arrival-rate',
      rate: 400,
      timeUnit: '1s',
      duration: '5m',
      preAllocatedVUs: 200,
      maxVUs: 200,
    },
  },
  setupTimeout: '3m',
};

const BASE_URL = __ENV.BASE_URL;
const PASSWORD = 'password12345678';

export function setup() {
  const tokens = [];
  for (let i = 0; i < 200; i++) {
    const res = http.post(`${BASE_URL}/v1/auth/user/login`,
      JSON.stringify({ nickname: `seed_${i}`, password: PASSWORD }),
      { headers: { 'Content-Type': 'application/json' } }
    );
    tokens.push(res.json('token'));
  }
  return { tokens };
}

export default function (data) {
  const userIdx = __ITER % 200;
  const token = data.tokens[userIdx];

  const startTime = Date.now() + (__ITER * 1000);

  const res = http.post(
    `${BASE_URL}/v1/schedules`,
    JSON.stringify({
      title: `s_${userIdx}_${__ITER}`,
      locationId: 1,
      startAt: new Date(startTime).toISOString(),
      endAt: new Date(startTime + 1800000).toISOString(),
    }),
    {
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${token}`,
      },
      timeout: '30s',
    }
  );

  check(res, { '201': (r) => r.status === 201 });
  check(res, { '401': (r) => r.status === 401 });
  check(res, { '406': (r) => r.status === 406 });

}
```  
  
- **측정 지표**:  
- **(1)** 응답 시간(평균, p(90), p(95), max) 및 RPS  
- **(2-1) sum(jvm_memory_used_bytes{job="rainmind-app", area="heap"}) / 1000 / 1000** JVM 힙 메모리 사용량  
- **(2-2) 100 * sum(jvm_memory_used_bytes{job="rainmind-app", area="heap"}) / sum(jvm_memory_max_bytes{job="rainmind-app", area="heap"})** JVM 힙 메모리 사용률  
- **(2-3) rate(jvm_gc_pause_seconds_sum{job="rainmind-app"}[1m]) * 1000** JVM Stop the world 시간  
- **(3) hikaricp_connections_active{job="rainmind-app", instance="app:8080"}** DB 커넥션 풀 사용량  
- **(4) container_memory_working_set_bytes{container_label_com_docker_compose_service="app"} / 1000 / 1000** 어플리케이션 총 메모리 사용량  
- **(5) sum(rate(container_cpu_usage_seconds_total{container_label_com_docker_compose_service="app"}[1m]))** CPU 사용량  
  
(결과 - findAllByUserId() 사용시(전))  
  
| avg | p(90) | p(95) | max | RPS(req / s) | JVM Heap Memory(MB) | JVM Heap Memory(%) | JVM Stop the world | DB 커넥션 풀 | App Total Memory(MB) | CPU Total |   
| --- | ----- | ----- | --- | ------------ | ------------------- | ------------------ | -------------- | ----------- | -------------------- | --------- |   
| 1.6s | 2.75s | 3.33s | 12.87s | 123.596799 | 359.12 | 17.61 | 36.25 | 44.48 | 1002.95 | 1.28 |     
  
(결과 - countByUserId() 사용시(후))  
  
| avg | p(90) | p(95) | max | RPS(req / s) | JVM Heap Memory(MB) | JVM Heap Memory(%) | JVM Stop the world | DB 커넥션 풀 | App Total Memory(MB) | CPU Total |   
| --- | ----- | ----- | --- | ------------ | ------------------- | ------------------ | -------------- | ----------- | -------------------- | --------- |   
| 104.24ms | 497.11ms | 759.8ms | 2.66s | 387.704068 | 171.05 | 8.39 | 4.78 | 1.95 | 589.60 | 0.79 |     
  
모든 부문에서 수치가 전반적으로 크게 개선되었다.  
특이사항: race condition 발생 가능  
  
(결과 - native query + SELECT LAST_INSERT_ID() 사용시(후))  
  
| avg | p(90) | p(95) | max | RPS(req / s) | JVM Heap Memory(MB) | JVM Heap Memory(%) | JVM Stop the world | DB 커넥션 풀 | App Total Memory(MB) | CPU Total |   
| --- | ----- | ----- | --- | ------------ | ------------------- | ------------------ | -------------- | ----------- | -------------------- | --------- |   
| 17.2ms | 9.25ms | 72.25ms | 1.82s | 398.995026 | 147.97 | 7.41 | 3.68 | 0.62 | 596 | 0.55 |    
  
countByUserId()와 비교하여, 수치가 또 한번 전반적으로 개선되었다.  
+ 왜 속도가 개선되었을까? SELECT LAST_INSERT_ID()를 이용하여, 멀티 스레드 환경에서도 가장 마지막에 삽입한 entity의 id를 안전하게 가져올 수 있게 하였으므로 별도의 .save() 과정이 필요없다. 즉 DB에 1번만 접근하면 된다. 또한 JPA 환경에서는, 엔티티의 변경 사항을 캡쳐하는 등 dirty checking 또한 발생 가능하다(현재는 JDBC라 해당 사항은 제외).  
  
특이사항: race condition 발생 가능. 내부의 SELECT문과 외부의 INSERT 문이 원자적 실행이 보장되지 않는다.  
  
+ MySQL의 SELECT문은 S-Lock을 획득하지 않고 MVCC 기반으로 동작하므로, Deadlock 위험은 없을 것으로 판단된다.  
  
따라서 이전 포스팅에서 기록했던 비관적 락 도입 또는 User 테이블 스키마 수정 후 '진짜' 원자적인 native query를 도입하는 것이 깔끔한 해결책이 될 것이다.  
  
현재 사용자 수에 따라 일정 제한이 30개로 지정되어 있어, 현재 스크립트만큼의 동시적인 요청이 들어오지는 않을 것으로 판단된다. 또한 현재 foreign key에 의해 user_id에 인덱스가 걸려있어, INSERT 문을 비관적 락으로 잠가도 다른 트랜잭션의 동작을 방해할 확률이 그다지 높지는 않을 것으로 예상된다.  
  
이 부분에 대해서는 고민을 해보아야겠다.